

### Title: PC-Fairness: A Unified Framework for Measuring Causality-based Fairness

### Publication: NeurIPS 2019, Vancouver, Canada, December 08-14, 2019
The Conference and Workshop on Neural Information Processing Systems (abbreviated as NeurIPS and formerly NIPS) is a machine learning and computational neuroscience conference held every December. The conference is currently a double-track meeting (single-track until 2015) that includes invited talks as well as oral and poster presentations of refereed papers, followed by parallel-track workshops that up to 2013 were held at ski resorts.

### Author：Yongkai Wu, Lu Zhang, Xintao Wu, and Hanghang Tong
Yongkai Wu is a 5th year PhD student from the Computer Science and Computer Engineering, University of Arkansas, advised by Prof. His research interests include Fairness-aware Machine Learning, Causal inference, and Big Data Analytics.

Lu Zhang is an Assistant Professor in Computer Science and Computer Engineering Department at University of Arkansas. His research interests lie in the field of data mining, machine learning, artificial intelligence, and distributed computing, particularly in discrimination/fairness-aware learning, causal modeling and inference, and data mining and privacy for genetic data.

Dr. Xintao Wu joined the Computer Science and Computer Engineering Department at the University of Arkansas as a professor in August 2014.  He was a faculty member in College of Computing and Informatics at the University of North Carolina at Charlotte from 2001 to 2014. Dr. Wu's major research interests include data mining, privacy and security, database application testing and big data analysis.  

Hanghang Tong is an Associate Professor at Department of Computer Science of University of Illinois at Urbana-Champaign. His research interests lie in large scale data mining and machine learning, especially for graph and multimedia data with applications to social networks analysis, healthcare, cyber-security and e-commerce.

### Paper Review
- Research Background
  1. Fair machine learning is now an important research field which studies how to develop predictive
machine learning models such that decisions made with their assistance fairly treat all groups of
people irrespective of their protected attributes such as gender, race, etc.
  2. A recent trend in this field is to define fairness as causality-based notions which concern the causal connection between protected
attributes and decisions.
  3. One common challenge of all causality-based fairness notions is identifiability. Unfortunately, in many situations causal effects are in general unidentifiable, referred to as unidentifiable situations.

- Problem to Solve
  1. Identifiability is a critical barrier for the causality-based fairness to be applied to real applications. 
  2. In previous works, simplifying assumptions are proposed to evade this problem. However, these simplifications may severely damage the performance of predictive models. One method
to bound indirect discrimination as the path-specific effect in unidentifiable situations, and another
method is proposed to bound counterfactual fairness. Nevertheless, the tightness of these methods is
not analyzed. 
  3. In addition, it is not clear whether these methods can be applied to other unidentifiable
situations, and more importantly, a combination of multiple unidentifiable situations.

- Key Design and Algorithm Proposed
  1. Key Design

  2. Algorighms

- Major Contribution

- Major limitation

- Something you don’t understand
  
- Your view on the research domain/topic/approach/data/solution  (positive or negative)

