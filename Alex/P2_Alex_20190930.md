

### Title: Automated Test Generation to Detect Individual Discrimination in AI Models

### Publication: arXiv:1809.03260
arXiv is an online digital archive for electronic preprints of scientific papers.

### Author：IBM Research AI, India. including Aniya Agarwal, Pranay Lohia, Seema Nagar et al.
IBM Research is one of the world’s largest and most influential corporate research labs

Aniya Agarwal

Pranay Lohia

Seema Nagar

### Paper Review
- Research Background
  1. Fairness is an increasingly important concern as machine learning models are used to support decision making in high-stakes applications such as mortgage lending, hiring, and prison sentencing. 
  2. Also fairness is a complex and multi-faceted concept that depends on context and culture, in some cases different definitions produce entirely different outcomes.
  3. In recent years several open source repositories have been developed to provide various levels of functionality in learning fair AI models.

- Problem to Solve
  1. It is impossible to satisfy all definitions of fairness at the same time and difficult to decide what is the right fairness metric.
  2. In addition to the multitude of fairness definitions, different bias handling algorithms address different parts of the model life-cycle, and understanding each research contribution, how, when and why to use it is challenging even for experts in algorithmic fairness.
  3. although fairness research is a very active area, and there are several libraries to provide various functionalities in this field, many of these deal only with bias detection, and provide no techniques for mitigating such bias.

- Key Design and Algorithm Proposed
  1. Key Design: This paper proposed a system named AIF360, which is the first system to bring together in one open source toolkit: bias metrics, bias mitigation algorithms, bias metric explanations, and industrial usability. And offered a rigorous architectural design focused on extensibility, usability, explainability, and ease of benchmarking that goes beyond the existing work.
  2. Algorighms
   - Pre-processing algorithms: Reweighing generates weights for the training examples in each (group, label) combination differently to ensure fairness before classification.
   - In-processing algorithms: Adversarial debiasing learns a classifier to maximize prediction accuracy and simultaneously reduce an adversarys ability to determine the protected attribute from the predictions. 
   - Post-processing algorithms: Equalized odds postprocessing solves a linear program to find probabilities with which to change output labels to optimize equalized odds.
    
- Major Contribution
  1. Offering an extensible architecture that incorporates dataset representations and algorithms for bias detection, bias mitigation, and bias metric explainability.
  2. Providing an empirical evaluation that demonstrates how AIF360 can be used for scientific comparisons of bias metrics and mitigation algorithms.
  3. Giving a design of an interactive web experience to introduce users to bias detection and mitigation techniques.
  
- Major limitation
  1. There are some measurements and mitigations of justice should to expand, such as compensatory justice, relating to the extent to which people are fairly compensated for harms done to them. 
  2. The variety of types of explanations offered need to extend, and should to create guidance for practitioners on when a specific kind of explanation is most appropriate.
  

- Something you don’t understand
  1. It is a littel challenging to fully understande the whole open source system, because which is a complex and comprehensive toolkit, including a variety of datasets, algorithms and bias metrics.
  

- Your view on the research domain/topic/approach/data/solution  (positive or negative)
  1. I hold a positive attitude towards this topic, as well as the solution which this paper proposed.  
  2. From my point of view, researching on fairness is useful and meaningful not only to individual, but also to whole society. The comprehensiveness of the open source system this paper proposed allows a user to not be hesitated in making the most appropriate choice. 

