

### Title: AI fairness 360: an extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias

### Publication: eprint arXiv:1810.01943 
arXiv is an online digital archive for electronic preprints of scientific papers

### Author：IBM Research, including Rachel K. E. Bellamy, Kuntal Dey, Michael Hind et al.
IBM Research is one of the world’s largest and most influential corporate research labs

Rachel K. E. Bellamy is the principal researcher and manager of human-AI collaboration at Thomas J. Watson Research Center, Yorktown Heights, NY USA. Recent research and design work has included work on cognitive user interfaces, studies of cognitive bias, design for mobile applications for hand-drawn computing, suport for business user's working with big data and interfaces for multi-factor mobile authentication.

Kuntal Dey is a Senior Software Engineer (Research) in IBM Research India, and is currently working with the Artificial Intelligence Engineering division in IBM Research India.

Michael Hind is a Distinguished Research Staff Member in the IBM Research AI department in Yorktown Heights, New York. His current research passion is in the general of area of Trusted AI, focusing on the fairness, explainability, transparency, and reliability of the construction of AI systems.

### Paper Review
- Research Background
Fairness is an increasingly important concern as machine learning models are used to support decision making in high-stakes applications such as mortgage lending, hiring, and prison sentencing. Also fairness is a complex and multi-faceted concept that depends on context and culture,in some cases different definitions produce entirely different outcomes.

- Problem to Solve


- Key Design and Algorithm Proposed


- Major Contribution
To introduce a new open source Python toolkit to help facilitate the transition of fairness research algorithms to use in an industrial setting and to provide a common framework for fairness researchers to share and evaluate algorithms.
  1. Offering a comprehensive set of fairness metrics for datasets and models, explanations for these metrics and algorithms to mitigate bias in datasets and models.
  2. Providing a gentle introduction to the concepts and capabilities for line-of-business users, extensive documentation, usage guidance, and industry-specific tutorials to enable data scientists and practitioners to incorporate the most appropriate tool for their problem into their work products.
  
- Major limitation

  

- Something you don’t understand

  

- Your view on the research domain/topic/approach/data/solution  (positive or negative)
