**Title: Resource Management with Deep Reinforcement Learning**

**Publication: HotNets 2016: Fifteenth ACM Workshop on Hot Topics in Networks,
November 9-10, 2016 — Atlanta, Georgia, USA**

The Fifteenth ACM Workshop on Hot Topics in Networks (HotNets-2016) will bring
together researchers in computer networks and systems to engage in a lively
debate on the theory and practice of networking. HotNets provides a venue for
discussing innovative ideas and for debating future research agendas in
networking.

**Author： Hongzi Mao (MIT), Mohammad Alizadeh (MIT), Ishai Menache (Microsoft
Research), Srikanth Kandula (Microsoft Research)**

-   Research Background

    -   Focused on solving scheduling problem based on Deep neural network and
        reinforcement learning (RL) algorithm

-   Problem to Solve

    -   Instead of using heuristic method to schedule this paper present a
        solution that translates the problem of packing tasks with multiple
        resource demands into a learning problem.

-   Key Design and Algorithm Proposed

    -   Reinforcement Learning

        -   Based on agent and environment design

        -   Works with basic Monte Carlo method

    -   Policy gradient method

        -   Focused on train the system and give feedback through reward
            function

        -   Agent design tasks and machines are passing to a neural network then
            after running the algorithm the highest task machine pair will be
            assigned to run

        -   Training algorithm is based on neural network training and they
            fixed alpha which is either is best to run the training or to
            improve it we need to update alpha based on each training batch

    -   Model

        -   Based on knowing information about jobs and duration

        -   Putting each machine resources in relative matrix

        -   Representing resources as vector to calculate the max between
            machine jobs and resources

        -   Training algorithm is based on reinforcement method

        -   Optimization can be done by updating the theta

-   Major Contribution

    -   Evaluation shows that DeepRM can be perform close to tetris and sfj
        algorithm and sometime even better

    -   Training can improve the system

-   Major limitation

    -   Locality and machine learning boundaries

        -   Assumption was based on one single resource pool

        -   Data locality

        -   Job models: no inner-task dependency was considered

        -   Bounded time horizon: DeepRM uses small time horizon to compute
            baseline

-   Something you don’t understand

-   Your view on the research domain/topic/approach/data/solution (positive or
    negative)

    -   Possible usage of PNN (probabilistic neural networks) to solve the same
        problem.

    -   Run a hybrid model with heuristic and RL
