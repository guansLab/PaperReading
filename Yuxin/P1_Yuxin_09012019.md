### Title: Generative Adversarial Networks

### Publication: NIPS

### Author: Ian Goodfellow et al.

### Paper Review
- Research Background

    Although there are many generative models existing, those models cannot learn enough probabilistic distributions from data, thus they cannot produce convincing fake data. Even though there are some works using two networks to learn from data, those works don't satisfy training criterion.

- Problem to Solve

    1. Difficult to approximate hard probabilistic computations in MLE.
    2. Difficult to use piecewise linear units in the generative context.

- Key Design and Algorithm Proposed

    1. Adding an adversarial network, discriminator, to estimate the data generated from the generative network.
    2. Discriminator and Generator play a minimax game which can help generator to generate data that is more close to original data.

- Major Contribution

    1. Using backprop instead of Markov chain to calculate gradients.
    2. Functions that are differentiable can be added in the model.

- Major Limitation

    1. Generator's distribution over data cannot be represented explicitly.
    2. There is no good synchronization between Discriminator and Generator during training.

- Something You Don't Understand

    I don't know why use backprop instead of Markov chains, and what is the advantage of backprop than Markov chains. 

- Your view on the research domain/topic/approach/data/solution (positive or negative)

    1. I think generative models in machine learning is promising, because these models can learn representations from given data and produce data with these representations.
    2. I think adding an adversarial network to help the generative network learning can make the learning more efficient.
    3. Their data is commonly used basic deep learning datasets which I think is not so challenging, and their way to evaluate the generated data is just using eyes to see difference between generated data and original data.
